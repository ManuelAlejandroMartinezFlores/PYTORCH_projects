{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Deep Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyro\n",
    "import pyro.distributions as D\n",
    "import pyro.distributions.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyro import poutine\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import SVI, TraceMeanField_ELBO\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.contrib.examples.polyphonic_data_loader as poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = poly.load_data(poly.JSB_CHORALES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([229]), torch.Size([229, 129, 88]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['sequence_lengths'].shape, data['train']['sequences'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emitter(nn.Module):\n",
    "    def __init__(self, input_dim, z_dim, emission_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(z_dim, emission_dim), nn.ReLU(),\n",
    "            nn.Linear(emission_dim, emission_dim), nn.ReLU(),\n",
    "            nn.Linear(emission_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return torch.sigmoid(self.model(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedTransition(nn.Module):\n",
    "    def __init__(self, z_dim, trans_dim):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(z_dim, trans_dim), nn.ReLU(),\n",
    "            nn.Linear(trans_dim, z_dim), nn.Sigmoid()\n",
    "        )\n",
    "        self.mean = nn.Sequential(\n",
    "            nn.Linear(z_dim, trans_dim), nn.ReLU(),\n",
    "            nn.Linear(trans_dim, z_dim)\n",
    "        )\n",
    "        self.loc = nn.Linear(z_dim, z_dim)\n",
    "        self.scale = nn.Linear(z_dim, z_dim)\n",
    "        \n",
    "        self.loc.weight.data = torch.eye(z_dim)\n",
    "        self.loc.bias.data = torch.zeros(z_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "        \n",
    "        \n",
    "    def forward(self, z):\n",
    "        gate = self.gate(z)\n",
    "        proposed_mean = self.mean(z)\n",
    "        loc = (1 - gate) * self.loc(z) + gate * proposed_mean\n",
    "        scale = self.softplus(self.scale(self.relu(proposed_mean)))\n",
    "        return loc, scale \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _model(self, minibatch, mini_batch_reversed, mini_batch_mask,\n",
    "          mini_batch_seq_lenghts, annealing_factor=1.):\n",
    "    Tmax = minibatch.size(1)\n",
    "    \n",
    "    pyro.module('dmm', self)\n",
    "    \n",
    "    z_prev = self.z0.expand(minibatch.size(0), self.z0.size(0))\n",
    "    \n",
    "    with pyro.plate('z_minibatch', len(minibatch)):\n",
    "        \n",
    "        for t in pyro.markov(range(1, Tmax + 1)):\n",
    "            z_loc, z_scale = self.trans(z_prev)\n",
    "            \n",
    "            with poutine.scale(None, annealing_factor):\n",
    "                z_t = pyro.sample(f'z_{t}', \n",
    "                                  D.Normal(z_loc, z_scale)\n",
    "                                    .mask(mini_batch_mask[:, t-1:t])\n",
    "                                    .to_event(1))\n",
    "                \n",
    "            emission_probs_t = self.emitter(z_t)\n",
    "\n",
    "            \n",
    "            pyro.sample(f'obs_{t}', \n",
    "                        D.Bernoulli(emission_probs_t)\n",
    "                            #.mask(mini_batch_mask[: t-1:t])\n",
    "                            .to_event(1),\n",
    "                        obs=minibatch[:, t-1, :])\n",
    "            \n",
    "            z_prev = z_t\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combiner(nn.Module):\n",
    "    def __init__(self, z_dim, rnn_dim):\n",
    "        super().__init__()\n",
    "        self.z_to_hidden = nn.Linear(z_dim, rnn_dim)\n",
    "        self.hidden_to_loc = nn.Linear(rnn_dim, z_dim)\n",
    "        self.hidden_to_scale = nn.Linear(rnn_dim, z_dim)\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softplus =  nn.Softplus()\n",
    "        \n",
    "    def forward(self, z_t_1, h_rnn):\n",
    "        h_comb = 0.5 * (self.tanh(self.z_to_hidden(z_t_1)) + h_rnn)\n",
    "        loc = self.hidden_to_loc(h_comb)\n",
    "        scale = self.softplus(self.hidden_to_scale(h_comb)) + 1e-9\n",
    "        return loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _guide(self, minibatch, minibatch_reversed, minibatch_mask,\n",
    "          minibatch_seq_lenghts, annealing_factor=1.):\n",
    "    \n",
    "    Tmax = minibatch.size(1)\n",
    "    \n",
    "    pyro.module('dmm', self)\n",
    "    \n",
    "    h0_contig = self.h0.expand(1, minibatch.size(0), self.rnn.hidden_size).contiguous()\n",
    "\n",
    "    rnn_out, _ = self.rnn(minibatch_reversed, h0_contig)\n",
    "    \n",
    "    rnn_out = poly.pad_and_reverse(rnn_out, minibatch_seq_lenghts)\n",
    "    \n",
    "    z_prev = self.zq0.expand(minibatch.size(0), self.zq0.size(0))\n",
    "    \n",
    "    \n",
    "    with pyro.plate('z_minibatch', len(minibatch)):\n",
    "        for t in pyro.markov(range(1, Tmax + 1)):\n",
    "            z_loc, z_scale = self.combiner(z_prev, rnn_out[:, t-1, :])\n",
    "            z_dist = D.Normal(z_loc, z_scale)\n",
    "            \n",
    "            with poutine.scale(None, annealing_factor):\n",
    "                z_t = pyro.sample(f'z_{t}',\n",
    "                                  z_dist.mask(minibatch_mask[:, t-1:t])\n",
    "                                  .to_event(1))\n",
    "                \n",
    "            z_prev = z_t \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMM(nn.Module):\n",
    "    def __init__(self, input_dim=88, z_dim=100, emission_dim=100, \n",
    "                 trans_dim=200, rnn_dim=500, rnn_dropout=0.0,\n",
    "                 num_iafs=0, iaf_dim=50):\n",
    "        super().__init__()\n",
    "        self.emitter = Emitter(input_dim, z_dim, emission_dim)\n",
    "        self.trans = GatedTransition(z_dim, trans_dim)\n",
    "        self.combiner = Combiner(z_dim, rnn_dim)\n",
    "        self.rnn = nn.RNN(input_dim, rnn_dim, nonlinearity='relu', batch_first=True,\n",
    "                          bidirectional=False, num_layers=1, dropout=rnn_dropout)\n",
    "        \n",
    "        self.z0 = nn.Parameter(torch.zeros(z_dim))\n",
    "        self.zq0 = nn.Parameter(torch.zeros(z_dim))\n",
    "        self.h0 = nn.Parameter(torch.zeros(1, 1, rnn_dim))\n",
    "        \n",
    "    def model(self, minibatch, mini_batch_reversed, mini_batch_mask,\n",
    "            mini_batch_seq_lenghts, annealing_factor=1.):\n",
    "        _model(self, minibatch, mini_batch_reversed, mini_batch_mask,\n",
    "          mini_batch_seq_lenghts, annealing_factor)\n",
    "        \n",
    "    def guide(self, minibatch, mini_batch_reversed, mini_batch_mask,\n",
    "          mini_batch_seq_lenghts, annealing_factor=1.):\n",
    "        _guide(self, minibatch, mini_batch_reversed, mini_batch_mask,\n",
    "          mini_batch_seq_lenghts, annealing_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmm = DMM()\n",
    "adam_params = {'lr': 3e-4, 'betas': (0.96, 0.999), 'clip_norm': 10.,\n",
    "               'lrd': 0.99996, 'weight_decay': 2.}\n",
    "optimizer = ClippedAdam(adam_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi = SVI(dmm.model, dmm.guide, optimizer, TraceMeanField_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_seq_lengths = data['train']['sequence_lengths']\n",
    "training_data_sequences = data['train']['sequences']\n",
    "test_seq_lengths = data['test']['sequence_lengths']\n",
    "test_data_sequences = data['test']['sequences']\n",
    "val_seq_lengths = data['valid']['sequence_lengths']\n",
    "val_data_sequences = data['valid']['sequences']\n",
    "N_train_data = len(training_seq_lengths)\n",
    "N_train_time_slices = training_seq_lengths.sum().item()\n",
    "N_mini_batches = int(N_train_data / 20 +\n",
    "                     int(N_train_data % 20 > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "annealing_epochs = 1000\n",
    "minimum_annealing_factor = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_minibatch(epoch, which_mini_batch, shuffled_indices):\n",
    "    if annealing_epochs > 0 and epoch < annealing_epochs:\n",
    "        # compute the KL annealing factor appropriate\n",
    "        # for the current mini-batch in the current epoch\n",
    "        min_af = minimum_annealing_factor\n",
    "        annealing_factor = min_af + (1.0 - min_af) * \\\n",
    "            (float(which_mini_batch + epoch * N_mini_batches + 1) /\n",
    "             float(annealing_epochs * N_mini_batches))\n",
    "    else:\n",
    "        # by default the KL annealing factor is unity\n",
    "        annealing_factor = 1.0\n",
    "\n",
    "    # compute which sequences in the training set we should grab\n",
    "    mini_batch_start = (which_mini_batch * 20)\n",
    "    mini_batch_end = np.min([(which_mini_batch + 1) * 20,\n",
    "                             N_train_data])\n",
    "    mini_batch_indices = shuffled_indices[mini_batch_start:mini_batch_end]\n",
    "    # grab the fully prepped mini-batch using the helper function in the data loader\n",
    "    mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths \\\n",
    "        = poly.get_mini_batch(mini_batch_indices, training_data_sequences,\n",
    "                              training_seq_lengths)\n",
    "    # do an actual gradient step\n",
    "    loss = svi.step(mini_batch, mini_batch_reversed, mini_batch_mask,\n",
    "                     mini_batch_seq_lengths, annealing_factor)\n",
    "    # keep track of the training loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_samples = 1\n",
    "\n",
    "def rep(x):\n",
    "    return np.repeat(x, n_eval_samples, axis=0)\n",
    "\n",
    "# get the validation/test data ready for the dmm: pack into sequences, etc.\n",
    "val_seq_lengths = rep(val_seq_lengths)\n",
    "test_seq_lengths = rep(test_seq_lengths)\n",
    "val_batch, val_batch_reversed, val_batch_mask, val_seq_lengths = poly.get_mini_batch(\n",
    "    np.arange(n_eval_samples * val_data_sequences.shape[0]), rep(val_data_sequences),\n",
    "    val_seq_lengths)\n",
    "test_batch, test_batch_reversed, test_batch_mask, test_seq_lengths = \\\n",
    "    poly.get_mini_batch(np.arange(n_eval_samples * test_data_sequences.shape[0]),\n",
    "                        rep(test_data_sequences),\n",
    "                        test_seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_evaluation():\n",
    "    # put the RNN into evaluation mode (i.e. turn off drop-out if applicable)\n",
    "    dmm.rnn.eval()\n",
    "\n",
    "    # compute the validation and test loss\n",
    "    val_nll = svi.evaluate_loss(val_batch, val_batch_reversed, val_batch_mask,\n",
    "                                 val_seq_lengths) / val_seq_lengths.sum()\n",
    "    test_nll = svi.evaluate_loss(test_batch, test_batch_reversed, test_batch_mask,\n",
    "                                  test_seq_lengths) / test_seq_lengths.sum()\n",
    "\n",
    "    # put the RNN back into training mode (i.e. turn on drop-out if applicable)\n",
    "    dmm.rnn.train()\n",
    "    return val_nll, test_nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [9:16:44<00:00, 11.13s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "pyro.clear_param_store()\n",
    "times = []\n",
    "vals = []\n",
    "tests = []\n",
    "\n",
    "for epoch in trange(3000):\n",
    "    # accumulator for our estimate of the negative log likelihood\n",
    "    # (or rather -elbo) for this epoch\n",
    "    epoch_nll = 0.0\n",
    "    since = time.time()\n",
    "    # prepare mini-batch subsampling indices for this epoch\n",
    "    shuffled_indices = np.arange(N_train_data)\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "\n",
    "    # process each mini-batch; this is where we take gradient steps\n",
    "    for which_mini_batch in range(N_mini_batches):\n",
    "        epoch_nll += process_minibatch(epoch, which_mini_batch, shuffled_indices)\n",
    "\n",
    "    # report training diagnostics\n",
    "    times.append(time.time() - since)\n",
    "    val, test = do_evaluation()\n",
    "    vals.append(val), tests.append(test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vals, label='validation')\n",
    "plt.plot(tests, label='test')\n",
    "plt.title('Evaluation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('NLL')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9784455f3e9463d14dc3263833cb7a66fe8439c0a7d698fd0d368a30d65f5d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
