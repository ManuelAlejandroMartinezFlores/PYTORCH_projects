{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 SVI Part III: ELBO Gradient Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{REINFORCE} = \\mathbb{E}_{q_\\phi} [f_\\phi (\\bold{z}) \\nabla_\\phi \\log q_\\phi (\\bold{z}) + \\nabla_\\phi f_\\phi (\\bold{z})] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.distributions.constraints as C\n",
    "import pyro\n",
    "import pyro.distributions as D\n",
    "# Pyro also has a reparameterized Beta distribution so we import\n",
    "# the non-reparameterized version to make our point\n",
    "from pyro.distributions.testing.fakes import NonreparameterizedBeta\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, TraceGraph_ELBO\n",
    "\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_abs_error(param, target):\n",
    "    return torch.abs(pyro.param(param) - target).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliBetaExample:\n",
    "    def __init__(self, max_steps):\n",
    "        self.max_steps = max_steps\n",
    "        self.alpha0 = 10.\n",
    "        self.beta0 = 10. \n",
    "        \n",
    "        self.data = torch.zeros(10)\n",
    "        self.data[0:6] = torch.ones(6)\n",
    "        self.n = 10\n",
    "        self.alpha = self.data.sum() + self.alpha0 \n",
    "        self.beta = - self.data.sum() + self.beta0 + self.n \n",
    "        \n",
    "        self.alphaq0 = 15. \n",
    "        self.betaq0 = 15. \n",
    "        \n",
    "    def model(self, decaying_base):\n",
    "        f = pyro.sample('fairness', D.Beta(self.alpha0, self.beta0))\n",
    "        \n",
    "        with pyro.plate('data', self.n):\n",
    "            pyro.sample('obs', D.Bernoulli(f), obs=self.data)\n",
    "        \n",
    "    def guide(self, decaying_base):\n",
    "        alpha = pyro.param('alpha', torch.tensor(self.alphaq0),\n",
    "                            constraint=C.positive)\n",
    "        beta = pyro.param('beta', torch.tensor(self.beta0),\n",
    "                           constraint=C.positive)\n",
    "        baseline_d = {'use_decaying_avg_baseline': decaying_base,\n",
    "                    'baseline_beta': 0.90}\n",
    "        pyro.sample('fairness', NonreparameterizedBeta(alpha, beta),\n",
    "                    infer=dict(baseline=baseline_d))\n",
    "        \n",
    "    def inference(self, decaying_base, tol=0.80):\n",
    "        pyro.clear_param_store()\n",
    "        optimizer = pyro.optim.Adam({'lr': 0.005, 'betas': (0.93, 0.999)})\n",
    "        svi = SVI(self.model, self.guide, optimizer, loss=TraceGraph_ELBO())\n",
    "        print(\"Doing inference with use_decaying_avg_baseline = %s\" % decaying_base)\n",
    "        \n",
    "        for k in trange(self.max_steps):\n",
    "            svi.step(decaying_base)\n",
    "            \n",
    "            alpha_e = param_abs_error('alpha', self.alpha)\n",
    "            beta_e = param_abs_error('beta', self.beta)\n",
    "            \n",
    "            if alpha_e < tol and beta_e < tol:\n",
    "                break \n",
    "            \n",
    "        print(f'Did {k+1} steps')\n",
    "        print(f'Final errors: alpha: {alpha_e:.4f}, beta: {beta_e:.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe = BernoulliBetaExample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing inference with use_decaying_avg_baseline = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9034/10000 [00:48<00:05, 186.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did 9035 steps\n",
      "Final errors: alpha: 0.7989, beta: 0.5866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bbe.inference(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing inference with use_decaying_avg_baseline = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1937/10000 [00:11<00:48, 165.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did 1938 steps\n",
      "Final errors: alpha: 0.7906, beta: 0.7996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bbe.inference(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9784455f3e9463d14dc3263833cb7a66fe8439c0a7d698fd0d368a30d65f5d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
